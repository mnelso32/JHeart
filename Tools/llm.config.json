{
  "provider": "openai-compatible",
  "endpoint": "http://localhost:11434/v1/chat/completions",
  "model": "glm-4.5-air",
  "apiKey": "env:LLM_API_KEY",
  "temperature": 0.7,
  "max_tokens": 2048,
  "extra_headers": {}
}
